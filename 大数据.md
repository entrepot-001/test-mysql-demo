## 学习大数据--《hadoop权威指南》
负载均衡：<br>
hdfs存储原理有一个存储元数据的Node和多个存储数据的DataNode<br>
分布式：把一块整体的数据分成若干个大小为128M的数据块，然后每个数据块存储到3个不同的服务器<br>
做集群：1.用快照的方式2.可以使用Docker做镜像；做集群的时要保证机器环境相同,主机和从机配置不同，从机之间完全相同<br>
## hadoop
hadoop的2.7.3
分组：

    Common 支撑其他3个组件的通用组件
    HDFS 分布式文件存储系统  存储文件
    Mappreduce 数据计算、数据分析、离线式、并行处理大数据集
    Yarn 用于作业调度

### HDFS（分布式文件系统）图
原理：分成等大的数据块默认时64M，默认存储到3个服务器上，这个块存储到DataNodes上；NameNode放的是目录
数据块（block）：真实的划分不是虚拟划分，可以修改在hadoop-default.xml文件中修改，也可以修改一个块可以存储到几个服务器上
RPC

## 安装hadoop
修改主机名hostname 名字和hosts IP+名字
修改salves文件为master

修改主机名
1.解压安装包，然后进入etc/hadoop

2.进入hadoop-env.sh配置文件
修改JAVA_HOME路径

3.yarn-env.sh
修改JAVA_HOME 改为jdk位置，默认情况是被注释上的
jdk位置后面＋"/"

4.core-stie.xml文件
configuartion内的数据
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://master:9000</value>
</property>
<property>
    <name>hadoop.tmp.dir</name>
    <value>/home/admin/hadoopdata</value>
</property>
记得改宿主目录，上面的宿主目录是admin
创建hadoopdata目录

5.hdfs-site.xml
主要的作用是复制
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

6.yarn-site.xml
<configuration>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
        <name>yarn.resourcemanager.address</name>
        <value>master:18040</value>
    </property>
	<property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>master:18030</value>
    </property>
	<property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>master:18025</value>
    </property>
	<property>
        <name>yarn.resourcemanager.admin.address</name>
        <value>master:18141</value>
    </property>
	<property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:18088</value>
    </property>
</configuration>

7.mapred-site.xml

复制mapred-site.xml.template 名为 mapred-stie.xml文件
/hadoop/mapred-site.xml.template 是hadoop框架自带的例子文件
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>

8.su -admin，用root用户命令也是可以的
~/.bash_profile
安装目录
export HADOOP_HOME=/usr/local/hadoop-2.7.3
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 
bin sbin

9.配置完成后：
source .bash_profile//配置文件重启
在hadoop-2.7.3 文件夹下
hdfs namenode -format

启动
cd hadoop-2.7.3
sbin/start-all.sh
在终端输入jps指令，用于查看当前系统的进程
会显示
ResourceManger
NameNode
Jps
SecondaryNameNode(单机版本时候没有)
DataNode
NodeManager
Jps

每次启动hadoop时：
1.进入home/admin文件夹中source .bash_profile  2.hdfs namenode -format  3.进入hadoop文件夹然后sbin/start-all.sh

http://localhost:50030
MapReduce的页面
http://localhost:50070
HDFS的页面
